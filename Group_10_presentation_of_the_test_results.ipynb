{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aa92796",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aa92796",
        "outputId": "4cf0b61b-e49d-43cd-9dee-9f489908d793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1035/1035 [==============================] - 1s 1ms/step\n",
            "1035/1035 [==============================] - 1s 1ms/step\n",
            "Test Results:\n",
            "                       MSE         R2\n",
            "XGBoost           0.003746   0.999976\n",
            "ELM             103.544449   0.346016\n",
            "NeuralNetwork  2060.526055 -12.014230\n",
            "Ensemble         31.752322   0.799453\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from skelm import ELMRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/e-shop clothing 2008.csv\", delimiter=';')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['year', 'month', 'day', 'session ID', 'model photography', 'page']\n",
        "df.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Check if 'price 2' column is present before dropping it\n",
        "if 'price 2' in df.columns:\n",
        "    df.drop('price 2', axis=1, inplace=True)\n",
        "\n",
        "# Perform label encoding for categorical variables\n",
        "encoders = {}\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        label_encoder = LabelEncoder()\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "        encoders[col] = label_encoder\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "\n",
        "# Selecting best features\n",
        "selected_features = ['page 1 (main category)', 'page 2 (clothing model)', 'colour', 'location']\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "# Wrapper class for Keras model\n",
        "class KerasRegressorWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y, epochs=100, verbose=0)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X).flatten()\n",
        "\n",
        "# Model Building\n",
        "# XGBoost\n",
        "xgb_model = XGBRegressor()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Extreme Machine Learning Model (ELM)\n",
        "elm_model = ELMRegressor()\n",
        "elm_model.fit(X_train, y_train)\n",
        "\n",
        "# Basic Deep Learning Model with two layers (Neural Network)\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Create wrapper for the Keras model\n",
        "keras_wrapper = KerasRegressorWrapper(model)\n",
        "\n",
        "# Ensemble model containing the top 3 models overall\n",
        "voting_model = VotingRegressor(estimators=[\n",
        "    ('XGBoost', xgb_model),\n",
        "    ('ELM', elm_model),\n",
        "    ('NeuralNetwork', keras_wrapper)\n",
        "])\n",
        "\n",
        "# Fit the voting regressor on the training data\n",
        "voting_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the models\n",
        "models = {\n",
        "    \"XGBoost\": xgb_model,\n",
        "    \"ELM\": elm_model,\n",
        "    \"NeuralNetwork\": keras_wrapper,\n",
        "    \"Ensemble\": voting_model\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[name] = {\"MSE\": mse, \"R2\": r2}\n",
        "\n",
        "# Presenting the test results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Test Results:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Score of models\n",
        "for name, model in models.items():\n",
        "  print(name,\" Model Score : \\n\", model.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOEJsDBlN7lw",
        "outputId": "187c8bc6-031a-4601-e27f-6be5e375b7a2"
      },
      "id": "LOEJsDBlN7lw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost  Model Score : \n",
            " 0.9999763409973748\n",
            "ELM  Model Score : \n",
            " 0.34601590429350826\n",
            "1035/1035 [==============================] - 2s 2ms/step\n",
            "NeuralNetwork  Model Score : \n",
            " -12.014229969501123\n",
            "1035/1035 [==============================] - 1s 1ms/step\n",
            "Ensemble  Model Score : \n",
            " 0.7994531471928811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from skelm import ELMRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/e-shop clothing 2008.csv\", delimiter=';')\n",
        "\n",
        "# Data cleaning\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['year', 'month', 'day', 'session ID', 'model photography', 'page']\n",
        "df.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "if missing_values.any():\n",
        "    print(\"Missing values detected. Handling missing values...\")\n",
        "    df.fillna(method='ffill', inplace=True)  # Forward fill missing values\n",
        "\n",
        "# Check if 'price 2' column is present before dropping it\n",
        "if 'price 2' in df.columns:\n",
        "    df.drop('price 2', axis=1, inplace=True)\n",
        "\n",
        "# Data preprocessing\n",
        "# Perform label encoding for categorical variables\n",
        "encoders = {}\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        label_encoder = LabelEncoder()\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "        encoders[col] = label_encoder\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "\n",
        "# Selecting best features\n",
        "selected_features = ['page 1 (main category)', 'page 2 (clothing model)', 'colour', 'location']\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "# Wrapper class for Keras model\n",
        "class KerasRegressorWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y, epochs=100, verbose=0)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X).flatten()\n",
        "\n",
        "# Model Building\n",
        "# XGBoost\n",
        "xgb_model = XGBRegressor()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Extreme Machine Learning Model (ELM)\n",
        "elm_model = ELMRegressor()\n",
        "elm_model.fit(X_train, y_train)\n",
        "\n",
        "# Basic Deep Learning Model with two layers (Neural Network)\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Create wrapper for the Keras model\n",
        "keras_wrapper = KerasRegressorWrapper(model)\n",
        "\n",
        "# Ensemble model containing the top 3 models overall\n",
        "voting_model = VotingRegressor(estimators=[\n",
        "    ('XGBoost', xgb_model),\n",
        "    ('ELM', elm_model),\n",
        "    ('NeuralNetwork', keras_wrapper)\n",
        "])\n",
        "\n",
        "# Fit the voting regressor on the training data\n",
        "voting_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the models\n",
        "models = {\n",
        "    \"XGBoost\": xgb_model,\n",
        "    \"ELM\": elm_model,\n",
        "    \"NeuralNetwork\": keras_wrapper,\n",
        "    \"Ensemble\": voting_model\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[name] = {\"MSE\": mse, \"R2\": r2}\n",
        "\n",
        "# Presenting the test results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"Test Results:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "QyrHpMU9Va7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01304233-207e-4e6e-e111-f38b8488a994"
      },
      "id": "QyrHpMU9Va7i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1035/1035 [==============================] - 1s 1ms/step\n",
            "1035/1035 [==============================] - 2s 1ms/step\n",
            "Test Results:\n",
            "                       MSE         R2\n",
            "XGBoost           0.003746   0.999976\n",
            "ELM             102.310890   0.353807\n",
            "NeuralNetwork  2075.365198 -12.107954\n",
            "Ensemble         25.973726   0.835951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Score of models\n",
        "for name, model in models.items():\n",
        "    print(name,\" Model Score : \\n\", model.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "4XeqpUNaWDkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ca1bf2-14fe-43b0-c3d4-6b9b1679b1f2"
      },
      "id": "4XeqpUNaWDkC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost  Model Score : \n",
            " 0.9999763409973748\n",
            "ELM  Model Score : \n",
            " 0.353807027808155\n",
            "1035/1035 [==============================] - 1s 1ms/step\n",
            "NeuralNetwork  Model Score : \n",
            " -12.107953618321693\n",
            "1035/1035 [==============================] - 1s 1ms/step\n",
            "Ensemble  Model Score : \n",
            " 0.8359506102563614\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}